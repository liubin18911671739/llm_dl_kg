# 知识融合模块

**知识融合模块**是 LLM-DL-KG 框架中的最后一个关键组成部分,主要目的是将从不同来源、不同粒度提取出的知识进行整合和融合,构建一个全局一致、高质量的知识库。知识融合需要解决实体对齐、知识去重、知识补全等问题,同时还要考虑知识的时效性和动态更新。

**输入**:

- 实体识别和关系抽取模块输出的局部知识图谱
- 外部结构化知识库(如 Freebase、WikiData 等)
- 其他非结构化文本数据(如新闻、论文等)

**输出**:

- 融合后的全局知识图谱

**主要步骤**:

1. **实体对齐**:

   - 实体对齐旨在识别不同知识源中指称相同实体的 mention,建立实体之间的等价关系
   - 传统的实体对齐方法主要基于字符串相似度、结构相似度等特征,如编辑距离、TF-IDF 等
   - 基于表示学习的方法将实体映射到低维语义空间,通过向量相似度进行对齐,如 TransE、GCN-Align 等
   - 基于大语言模型的实体对齐方法,通过 prompt 引入上下文信息,判断两个实体描述是否指称同一实体:

     $P(e_1 \equiv e_2|\mathbf{X}_1,\mathbf{X}_2) = \sigma(\mathrm{FFN}(\mathbf{h}_\mathrm{[CLS]}))$

     其中 $\mathbf{X}_1$, $\mathbf{X}_2$ 为两个实体的上下文描述, $\mathbf{h}_\mathrm{[CLS]}$ 为 BERT/RoBERTa 输出的[CLS]向量

2. **知识融合策略**:
   - 基于置信度的策略:为每个知识三元组 $(e_h,r,e_t)$ 估计一个置信度分数,综合多个知识源的证据,选择置信度最高的三元组
   - 基于真值发现的策略:构建知识源-实体-属性的三部图,通过置信度传播算法如 TruthFinder、PooledInvestment 等估计每个知识的可信度
   - 基于规则和本体的策略:人工定义一组规则和本体约束,对候选知识进行过滤、修正和补全,提高知识的质量和一致性
   - 基于表示学习的策略:通过知识表示学习将实体和关系映射到一个语义空间,利用向量运算实现知识的聚类、推理和融合
3. **动态知识更新**:
   - 知识图谱需要持续吸收新的知识,同时修正已有知识中的错误和过时信息
   - 增量更新策略:将新加入的实体、关系插入已有知识图谱,同时进行必要的修改和删除操作,保持图谱的一致性
   - 时间感知策略:引入时间戳信息,建立知识的时间版本,支持特定时间点的图谱查询和分析
   - 大语言模型的持续学习策略:利用新的文本数据持续训练大语言模型,定期生成新版本的知识库,实现知识的自动更新
4. **知识冲突解决**:
   - 知识冲突是指不同来源之间存在矛盾或不一致的知识,需要进行识别和调停
   - 基于规则的方法:人工定义一组规则,如 functionality、inverse functionality 等,用于检测和消解知识冲突
   - 基于置信度的方法:比较冲突知识的置信度,选择置信度更高的知识作为最终结果
   - 基于议题模型的方法:引入议题模型如 LDA、LSA 等,将实体和关系划分为不同的主题,在主题层面进行知识融合和冲突解决
   - 基于大语言模型的方法:利用大语言模型的常识推理能力,通过 prompt 引入外部知识,对冲突知识进行 consistency check 和调停

知识融合模块综合利用深度学习、知识表示、图神经网络、规则推理等技术,将多源异构的知识整合为一致、规范的知识库。其中,大语言模型的知识增强和推理能力为实体对齐、知识融合、动态更新等任务提供了新的思路和方法。知识融合的结果既可以作为端到端知识图谱构建的输出,也可以为实体识别、关系抽取等任务提供高质量的先验知识,形成知识协同更新的良性循环。知识融合的效果直接影响到知识图谱的质量和应用价值。
