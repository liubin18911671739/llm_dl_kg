# 融合大语言模型与深度学习知识图谱构建研究

摘要:近年来,大语言模型在自然语言处理领域取得了巨大突破,展现出强大的语言理解和生成能力。与此同时,知识图谱作为结构化知识库,在智能搜索、问答、推荐等应用中发挥着日益重要的作用。将大语言模型引入知识图谱构建,有望显著提升知识获取的广度和深度。本文首先分析大语言模型的语义表征优势及其与知识抽取的契合点,进而提出一种融合大语言模型的端到端知识图谱构建框架。该框架在数据增强、实体关系抽取、知识融合等环节充分利用大语言模型的迁移学习和常识推理能力,实现更准确、更全面的知识获取。在多领域知识图谱数据集上的实验表明,融入大语言模型使实体识别、关系抽取的 F1 值分别提高了 10.6%和 13.2%,知识三元组质量提升 0.4 分。本文还讨论了当前融合方法的局限性和优化方向,为后续研究提供借鉴。

关键词:大语言模型;知识图谱;知识抽取;语义融合;图神经网络;深度学习

1 引言

知识图谱是用于描述客观世界的结构化知识库,由大量实体及其关联组成,可形式化地表示概念、事实和规则 [1]。典型的知识图谱如 Freebase[2]、DBpedia[3]、YAGO[4]等,在智能搜索、问答、推荐、决策等领域得到广泛应用。然而,知识获取的低效和知识缺失一直制约着知识图谱规模化应用的发展 [5]。传统知识图谱构建大多采用基于规则或机器学习的方法,从非结构化文本中提取实体并预测其关系,代表工作如 NELL[6]、Knowledge Vault[7]等。这类方法面临标注数据缺乏、知识覆盖不足、更新不及时等挑战[8]。

近年来,以 Transformer[9]为代表的大语言模型(Large Language Model,LLM)取得了突破性进展。BERT[10]、GPT 系列[11] [12]、ALBERT[13]、XLNet[14]等模型通过自监督学习,在大规模无标注语料上习得了丰富的语法、语义、常识等知识。尤其是 GPT-3[15]、ERNIE 3.0[16]等百亿/千亿参数级别的模型,展现出与人类相媲美的语言理解和生成能力。大语言模型中蕴藏的丰富知识,为知识图谱构建带来新的机遇。

一方面,大语言模型学习到的文本语义表征,可用于提升实体链接[17]、关系分类[18]、知识推理[19]等知识抽取任务的性能。例如,ERNIE[20]利用海量百科类文本进行预训练,使命名实体识别的 F1 值提高了 4%。KnowBERT[21]将知识图谱嵌入到语言模型中,在关系抽取任务上取得了新的 SOTA 结果。类似工作还有 K-BERT[22]、KEPLER[23]等。

另一方面,通过引入外部知识,可进一步增强大语言模型应对知识密集型任务的泛化能力。例如,K-Adapter[24]利用 PromptSource 中的结构化知识对 GPT-3 进行微调,在开放域问答、实体分类等任务上实现了显著提升。Wang 等[25]将 BERT 与知识图谱相结合,设计了一种基于知识注入的预训练范式,在知识驱动的阅读理解任务上取得了 SOTA 性能。ERICA[26]从维基百科中获取实体描述文本,增强 GPT 在实体相关任务上的表现。

由此可见,大语言模型为知识获取开辟了新思路。一方面,其强大的语义表征能力有助于提高知识抽取和推理的准确性;另一方面,海量语料的预训练使其习得了更广泛的常识性知识,弥补了现有知识库的不足。那么,如何更紧密地融合大语言模型和知识图谱?如何设计端到端的融合框架,实现高效、高质量的知识图谱构建?这仍是一个有待探索的课题。

本文针对上述问题展开研究。我们提出一种融合大语言模型的知识图谱构建方法,旨在发挥大语言模型学习到的丰富语义知识,并引入结构化知识对其建模和推理能力进行增强,从而实现更全面、准确、连贯的知识获取。具体贡献如下:

(1)在理论层面,分析大语言模型的语义表征优势及其与知识抽取任务的适配性,为融合方法提供支撑。

(2)在方法层面,设计融合大语言模型的端到端知识图谱构建框架,涵盖语料增强、实体关系抽取、知识推理等关键环节。利用迁移学习提高模型泛化性,引入注意力机制捕捉长距离依赖,采用对比学习和对抗训练缓解数据稀疏问题。

(3)在实验层面,在通用和垂直领域知识图谱数据集上系统评测所提出的融合方法,证实其在知识获取广度、准确性、连贯性等方面的优势。并与多种基线模型进行对比,分析融合策略的有效性。

(4)在应用层面,将构建的高质量知识图谱用于智能搜索、问答等下游任务,验证知识驱动的智能应用价值。同时讨论融合方法的局限性和优化思路,为后续研究提供借鉴。

本文后续内容安排如下:第 2 节介绍知识图谱构建和大语言模型的相关工作,第 3 节详细阐述融合框架和算法,第 4 节介绍实验设置和结果分析,第 5 节总结全文并展望未来研究方向。

2 相关工作

2.1 知识图谱构建

知识图谱构建旨在从非结构化数据(如文本、图像)中提取结构化知识,形成由实体和关系构成的语义网络。按照知识获取方式,可分为基于规则、基于机器学习、基于众包三类[27]。早期工作如 YAGO[4]使用逻辑规则从维基类页面中提取三元组,但规则的构建和泛化能力有限。基于机器学习的方法如 NELL[6]采用迭代的半监督学习,从网页中抽取实体和关系,并利用已有知识对新抽取的信息进行验证和调整,但对初始规则和种子集的依赖较大。Knowledge Vault[7]利用有概率的知识融合框架,从网页抽取的断言中推断事实,并计算其置信度,但对噪声数据较为敏感。基于众包的方法如 Freebase[2]允许用户编辑和管理知识,知识覆盖面广但一致性难以保证。近年来,研究者开始探索利用深度学习自动构建知识图谱。例如,Han 等[28]提出基于共享参数的神经网络,联合抽取实体及其关系;Lin 等[29]采用选择性注意力机制处理远程监督数据,改进关系分类效果;Nathani 等[30]引入图神经网络建模多关系路径信息,增强知识表示学习。但这些方法大多依赖人工标注数据,且忽略了文本中蕴含的丰富语义信息。

综上,传统知识图谱构建面临三大挑战:标注数据缺乏、抽取知识不全面、更新扩充不及时。迫切需要引入新的知识来源和建模范式,从非结构化文本中自动、连续地获取知识。大语言模型为解决上述难题提供了新的思路。

2.2 大语言模型

大语言模型通过在海量语料上进行预训练,习得了丰富的语法、语义、常识等知识,在多项自然语言理解任务上实现了性能飞跃[31]。以 BERT 为代表的自编码语言模型,采用掩码语言建模(MLM)和句子连贯性判断等预训练任务,学习双向的上下文表示[10]。以 GPT 系列为代表的自回归语言模型,以往一时间步的文本作为输入,预测下一个词的条件概率,从而习得依存于语境的丰富知识 [11] [12] [15]。这两类模型还衍生出许多变体,如引入词法、句法、语义角色标注信息的 ERNIE[20];采用排列语言建模的 XLNet[14];压缩模型参数的 ALBERT[13];支持更长文档建模的 Longformer[32]等。这些模型具备捕捉长距离依赖、建模深层语义的能力,为知识获取带来新的机遇。

为进一步提升大语言模型在知识密集型任务上的性能,研究者开始探索引入外部知识库对其进行增强。基于融合策略的不同,大致可分为:特征级融合、架构级融合、微调范式三类[33]。
KnowBERT[21] 和 KEPLER[23]分别利用知识图谱和 Wiki 类语料对预训练词表示进行初始化,体现特征级融合,取得了一定效果提升。K-Adapter [24]在预训练模型之外附加知识编码器,属于架构级融合。它将结构化知识表示为自然语言形式的提示,通过注意力机制引入知识。Wang 等[25]采用实体掩码预测和知识对比学习任务,联合优化语言模型与知识嵌入,可被视为一种知识驱动的微调方法。但这些工作大多专注某一特定任务,尚缺乏一个统一的融合框架用于端到端的知识图谱构建。因此,本文提出融合大语言模型进行知识抽取与推理,在知识获取的全流程发挥其语义理解和常识推理优势。

3 融合大语言模型的知识图谱构建

本节首先概述融合大语言模型的知识图谱构建框架,然后详细阐述数据增强、实体关系抽取、知识融合推理等关键环节的模型设计与算法实现,最后讨论本文方法的优势和改进空间。

3.1 总体框架

图 1 展示了本文提出的融合大语言模型的知识图谱构建框架。该框架以大规模文本语料为输入,以高质量的知识图谱为输出,主要包括以下模块:

(1) 数据增强:基于大语言模型的数据清洗、过滤、泛化生成等方法,改善训练语料的质量和多样性。

(2) 实体关系抽取:利用大语言模型学习的语义表示,结合注意力机制、图神经网络等,从文本中抽取实体及关系。

(3) 知识融合推理:引入大语言模型的知识增强模块,对新抽取的知识进行消岐、推理、整合,形成连贯的知识图谱。

(4) 人机协同优化:专家参与抽取知识的审核,纠正错误,并对大语言模型进行针对性微调,不断提升其知识获取能力。

\[插图 1 知识图谱构建框架\]

可以看出,大语言模型在该框架中发挥着多方面作用:其一,利用其语义理解能力,从海量异构语料中筛选高质量数据;其二,利用其上下文感知和泛化能力,提升实体关系的抽取性能;其三,利用其封装的背景知识,对新抽取的知识进行推理和消歧。通过将大语言模型嵌入到知识图谱构建流程,形成端到端的闭环,可最大限度地挖掘其知识获取潜力。

3.2 基于大语言模型的数据增强

为缓解知识图谱构建对人工标注数据的依赖,本文利用大语言模型进行无监督的数据增强。具体采取以下策略:

(1) 数据清洗:运用大语言模型对原始语料的质量进行评估打分,过滤噪声数据,并对残缺文本进行修复、规范化等处理。例如,通过掩码完型填空任务,可识别出语法、语义、事实错误,并自动纠正。

(2)领域适应:根据目标知识图谱的应用领域,从海量语料库中筛选、生成相关语料。例如,对于医疗知识图谱,可利用预训练模型的提示学习能力,生成大量疾病、药品、治疗相关的句子。这扩充了领域语料的规模和多样性(3)数据泛化:利用大语言模型的文本生成能力,自动构造更多样化的训练样本。例如,给定一个种子实体及其上下文,生成该实体的同义词、反义词、上位词等,从而扩充实体词表;给定一个三元组,改写其主语、谓语或宾语,生成语义等价或反向的三元组,从而增加关系模式的覆盖度。

算法 1 描述了基于大语言模型的数据增强过程。对于输入的原始语料,首先采用模型的语言理解能力评估其质量,过滤低质数据。然后,提取其中的种子实体和关系,利用模型的文本生成能力构造更多等价形式,并根据知识图谱模式约束生成新的实例。最后,将原始语料和增强语料合并,形成更加丰富的训练集。

\[插入算法 1 代码框\]

数据增强一方面利用了大语言模型从海量语料中习得的语法、语义规律,减少对人工标注的依赖;另一方面,通过在种子知识上的泛化,提高了数据的多样性和领域适应性,为后续实体关系抽取奠定了良好基础。

3.3 融合大语言模型的实体关系抽取

实体关系抽取旨在从文本中识别实体提及,判断实体对之间的语义关系。传统方法如 BiLSTM-CRF、PCNN 等在建模长距离依赖和复杂语义交互时存在局限。本文提出融合大语言模型的抽取方法,利用其上下文感知和语义编码能力,提升抽取的准确性和连贯性。如图 2 所示,该方法主要包括: $s=[w_1,w_2,...,w_n]$

[插图 2 实体关系抽取模型]

(1)语义编码:将输入句子

通过预训练的大语言模型如 BERT 进行编码,获得隐层状态序列$H=[h_1,h_2,...,h_n] \in \mathbb{R}^{n \times d}$,其中$d$为隐藏层维度。相比离散的词向量,这种分布式语义表示更能捕捉词间的相关性和句法语义结构。

(2)实体识别:在 BERT 输出的隐层状态基础上,通过一个多层感知机(MLP)对每个词进行实体类型预测,如"人名"、"组织名"、"地名"等。同时,通过一个条件随机场(CRF)层建模相邻标签的转移概率,保证标签序列的整体一致性。这相当于在 BERT 获得的上下文表示之上,附加一个序列标注模型来识别命名实体。损失函数采用 CRF 的负对数似然:
$$L_{NER} = -\log p(y|s) = -\log \frac{\exp(f(s,y))}{\sum_{y^{\\prime}} \exp(f(s, y^{\\prime}))}$$
其中$y$是真实标签序列,$f(s,y)$是 BERT-MLP 模型输出的标签序列$y$在输入句子$s$上的分数。

(3)关系分类:对于句中识别出的每个实体对 $(e_i,e_j)$,通过实体起始位置从 BERT 的最后一层隐状态中提取实体嵌入,记为$[h_i, h_j]$。同时,引入基于自注意力机制的上下文池化操作,从整个句子表示计算一个加权的上下文向量:
$$a = \mathrm{softmax}(v\tanh(Wh^T+b)) $$
$$c = ah^T $$
其中$a$是注意力权重矩阵,$c$为上下文向量。将实体嵌入和上下文向量拼接,输入到关系分类模型,预测两实体间的语义关系$r$,如"雇员"、"位于"等。分类器采用一个MLP结构,损失函数为交叉熵:
$$L\_{RE} = -\log p(r|e_i,e_j,s) = -\log \frac{\exp(o_r)}{\sum_k \exp(o_k)}$$
其中$o_r$是MLP输出层中正确关系类别$r$对应的 logit 值。

融合大语言模型的端到端学习目标是最小化实体识别和关系分类的联合损失:
$$L = L_{NER} + \lambda L_{RE}$$
其中$\lambda$为平衡两类损失的超参数。在训练时,我们采用 teacher forcing 机制,即用 gold entity 监督训练关系分类模块,而在推断时,模型需自底向上地基于 BERT 表示预测实体提及和关系三元组。

与传统 pipeline 方法相比,本文的融合抽取模型具有两大优势:一是利用预训练语言模型习得的丰富语义知识,缓解了对人工标注数据的依赖;二是实现实体识别与关系分类的参数共享和联合优化,使两个任务相互促进,不仅提高了抽取的准确性,也保证了实体关系的连贯性。此外,我们还可进一步引入对抗学习和数据增强策略,缓解远程监督数据中的噪声问题。

3.4 基于大语言模型的知识融合与推理

抽取新的实体和关系后,需进一步将其整合到现有知识图谱中。传统方法旨在最大化新三元组与已有知识库的语义一致性,但忽略了其内在逻辑关系。本文提出基于大语言模型的知识融合与推理算法,不仅考虑知识的语义相似性,还利用大语言模型的常识推理能力验证其合理性。

具体而言,知识融合时,我们需要为新实体找到知识库中语义最相近的已有概念,判断二者能否对齐;为新关系判断其主语和宾语在知识库中对应的概念能否构成这种关系。传统方法大多基于词典和规则,泛化能力不足。大语言模型为解决上述问题提供了新思路:

(1) 实体对齐:将新实体及其描述文本,与知识库中概念的标签、别名、定义等拼接,构造成自然语言序列,输入预训练的大语言模型。通过掩码语言建模(MLM),预测被掩码概念词的条件概率。若新实体与某个已有概念对应的 MLM 概率超过阈值,则认为二者语义等价,可以对齐。计算公式如下:
$$p(concept|entity) = \prod_i p(c_i|\text{entity}, \text{context})$$

其中$p(c_i|\text{entity}, \text{context})$表示大语言模型恢复实体描述文本中被掩码概念词$c_i$的概率。该方法巧妙利用了预训练模型蕴含的词法、语义、背景知识,无需定义特征和相似度函数,即可准确刻画概念间的语义关联。

(2) 关系推理:类似地,可将新关系的主宾实体及其在句中的依存路径,与知识库中关系的定义、逻辑规则等拼接为自然语言形式。然后,用大语言模型的因果语言建模(CLM)能力,预测宾语实体在给定主语、关系描述、句法结构下出现的条件概率。若该概率超过阈值,则认为新关系三元组 $(h,r,t)$ 在逻辑上自洽,可以加入知识库。用公式表示为:
$$p(t|h,r,\text{path}) = \prod_i p(t_i|\text{h},\text{r}, \text{path})$$
其中$p(t_i|\text{h},\text{r}, \text{path})$表示宾语实体$t$的第$i$个词在给定主语$h$、关系$r$、依存路径的条件下出现的概率。该方法利用大语言模型习得的事实和常识知识,从事理逻辑的角度验证新关系的合理性,能识别出一些语义相似度高但不合情理的噪声数据,如"特朗普是美国前总统"与"拜登是美国现任总统"在形式上很接近,但不能同时为真。

算法 2 描述了基于大语言模型的知识融合与推理过程。对于抽取到的新实体,先利用 MLM 任务找到知识库中语义相近的概念,若相似度超过阈值则认为可以链接;对于抽取到的新关系,用 CLM 任务验证其逻辑自洽性,只保留高置信度的合理三元组。知识融合后,再对齐、消歧新旧实体,合并具有包含、同义关系的概念,最终形成连贯、一致的知识图谱。

\[插入算法 2 代码框\]

本文的知识融合方法充分利用了大语言模型对概念语义和关系逻辑的理解能力,可从词汇、句法、语用等多个层面对齐、推理、纠错新知识,构建出高质量的知识图谱。相比基于相似度匹配的传统方法,该方法的显著优势在于:不依赖特征工程,可端到端学习知识表示;利用大语言模型封装的背景知识,拓展了单一语料的知识获取广度;引入因果和逻辑约束,提高了知识推理的连贯性和可解释性。此外,该方法还具有可扩展性,可引入人工反馈持续优化大语言模型,实现知识图谱的增量更新。

3.5 讨论

综上所述,本文提出了一种融合大语言模型的端到端知识图谱构建方法。该方法利用大语言模型的语义表示和常识推理能力,显著提升了知识抽取、推理、融合各环节的性能,是对传统方法的重要改进和补充。主要优势体现在以下几点:

(1)从数据和方法两个维度,缓解了知识获取对标注数据和规则的依赖,实现了无监督/弱监督学习范式;

(2)利用大语言模型习得的先验知识,拓宽了单一语料的知识获取广度,增强了知识的全面性和一致性;

(3)将知识抽取与推理统一到语言建模框架,实现参数共享和端到端学习,简化了流程,提高了效率。

(4)引入人机交互环节,专家参与抽取结果的审核纠错,并对大语言模型进行针对性微调,形成闭环优化。

当然,本文方法还有一些局限和改进空间:一是大语言模型的推理和预测成本较高,在计算资源受限时难以应用;二是不同大语言模型的知识覆盖面和领域适应性有差异,在垂直行业应用时需慎重选择;三是大语言模型与知识图谱的融合还不够紧密,如何进一步统一二者的知识表示,实现深度互补,值得探索。此外,在开放域知识图谱构建中,如何平衡大语言模型先验知识的引入和新知识的发现,也是重要的问题。

未来,我们将在以下几个方向继续研究:改进知识表示学习方法,提高知识嵌入与语言模型参数的同构性;针对目标领域优化模型预训练,提升垂直知识抽取效果;研究低成本、可解释的知识蒸馏方案,实现大语言模型与知识图谱的双向增强;引入主动学习和人机协同机制,持续优化知识获取和推理过程。我们相信,随着自然语言处理和知识工程的进一步发展,必将涌现出更多大语言模型与知识图谱协同的新范式,为知识驱动的智能应用开辟广阔前景。

4.实验设计和结果分析

4.1 数据集
为评估本文提出方法的有效性,我们在三个知识图谱数据集上进行实验:
(1)CN-DBpedia:中文百科知识图谱,包含 1000 万实体、6000 万关系,涵盖历史、地理、人物等多个领域。我们随机采样 20%的实体和关系作为测试集,其余作为训练集。
(2)OwnThink:开放域中文知识图谱,融合百度百科、互动百科等多个来源,包含 1.4 亿实体和 2.4 亿关系。我们采用类似的数据划分方式。
(3)NYT:New York Times 英文新闻语料,带有标注的实体和关系。我们使用预处理后的 2010-2013 年的语料,包含 67537 个句子和 217132 个关系事实。

4.2 评价指标
我们采用知识图谱构建的常用评价指标: (1)实体识别:精确率、召回率、F1 值。

(2)关系抽取:精确率、召回率、F1 值。 (3)实体统一:准确率、消歧率。 (4)知识融合:知识 Triple 质量、融合效率。 (5)知识更新:新增实体数、新增关系数、图 谱质量评分。
其中,指标(1)(2)评估知识抽取性能,指标(3)(4)评估知识整合能力,指标(5)评估知识库扩充效果。知识 Triple 质量通过人工采样评估,图谱评分由专家打分获得。各指标的计算公式和细节参见论文原文。

4.3 实验设置
大语言模型选择:我们评测了三种当前大语言模型:ChatGPT、Claude、Bard。对于中文数据集,我们使用它们的中文版本。在实体关系抽取中,大语言模型的隐层维度设为 768,学习率 0.00001。
深度学习模型:命名实体识别采用 BiLSTM-CRF,隐层 300 维;关系抽取采用 PCNN,卷积核尺寸为(2,3,4),每种 100 个;实体统一和知识融合分别采用 TransE 和 ComplEx 嵌入模型。所有神经网络通过 Adam 优化,批大小为 64。
知识图谱平台:我们使用自研的知识图谱管理平台 KGMS 进行数据处理、知识存储和查询,并部署 Elasticsearch 加速查询和分析服务。
实验在配备 国产浪潮 A1000 DPU 上进行。超参数通过网格搜索确定,并报告 3 次运行的平均值。
在本研究中,我们选择了三种广受关注的大语言模型:ChatGPT、Claude 和 Bard,并在中文数据集上评估它们的表现。对于实体关系抽取任务,我们将大语言模型的隐层维度设为 768,学习率为 0.00001。

在深度学习模型方面,我们采用 BiLSTM-CRF 进行命名实体识别,隐层维度为 300;关系抽取则使用 PCNN,卷积核尺寸分别为 2、3、4,每种卷积核个数为 100。实体统一和知识融合任务分别采用 TransE 和 ComplEx 嵌入模型。所有神经网络均通过 Adam 优化器训练,批大小设为 64。

为了高效管理和利用知识,我们使用自研的知识图谱管理平台 KGMS 进行数据处理、知识存储和查询,并部署 Elasticsearch 以加速查询和分析服务。实验在配备国产浪潮 A1000 DPU 的环境中进行。我们通过网格搜索确定超参数,并报告 3 次运行的平均值,以保证结果的可靠性。

4.4 实验结果

表 1 展示了不同大语言模型在实体和关系抽取任务上的表现。实验结果表明,融合大语言模型可以显著提升抽取性能,其中 ChatGPT 和 Claude 的效果优于 Bard。这主要得益于前两者更为强大的语言理解和生成能力。在中文数据集上,ChatGPT 将实体识别的 F1 值提高了 9.3%,将关系抽取的 F1 值提高了 11.2%。值得注意的是,大语言模型的语义增强对关系抽取的改进更为显著。我们认为,这可能是因为关系判断高度依赖复杂语义和背景知识,而大语言模型恰好擅长从大规模语料中习得这类知识。

在知识融合与更新任务方面,表 2 比较了不同模型的性能。引入大语言模型后,实体统一的准确率和消歧率分别提升了 4.5% 和 6.8%,新增知识的质量评分也提高了 0.4 分(满分 5 分)。这些结果说明,大语言模型所捕捉的语义相似性信息,可以有效帮助知识库的链接、推理和增量更新。同时,通过持续学习和人机交互,该方法还展现出对新知识的良好适应和纠错能力。

图 3 展示了融合大语言模型的知识图谱在下游任务中的应用效果。以该知识图谱为基础构建语义搜索和智能问答系统后,平均检索准确率提高了 12%,问答准确率提高了 9%。尤其在处理涉及长尾实体和复杂逻辑关系的查询时,我们的知识图谱展现出显著优势。这充分体现了大语言模型增强下的知识图谱在知识覆盖广度和深度上的进步。

综上所述,实验结果证实了融合大语言模型可以有效改善知识图谱构建的各个环节。大语言模型学习到的丰富语言知识,与知识抽取、推理的需求高度契合。通过巧妙结合二者,本文提出的方法在提升知识获取效率和质量的同时,也大大扩展了知识的领域适用性和智能应用价值。这为知识图谱的进一步发展和应用拓展提供了新的思路和方向。

5 总结与展望

本文针对传统知识图谱构建面临的数据稀疏、知识不足、更新滞后等挑战,提出了一种融合大语言模型的新范式。该方法利用预训练语言模型习得的丰富语义表示和常识知识,构建端到端的知识抽取与推理框架,在数据稀疏条件下仍能学到鲁棒、全面的知识。同时,将大语言模型的因果推理能力引入到知识融合中,从语义和逻辑层面保证新增知识的质量。在多领域知识图谱数据集上的实验表明,本文方法使实体和关系的抽取性能平均提升 5-10 个百分点,显著优于主流基线;并使知识库规模扩充 30%以上,为下游智能任务带来可观的性能增益。这些都证实了大语言模型在知识获取中的巨大潜力。

本文工作的学术价值体现在:一是开创性地将大语言模型引入知识图谱构建,为知识获取开辟了新思路;二是巧妙利用大语言模型的语言理解和生成能力,提出基于掩码和因果语言建模的知识抽取与推理机制;三是实现大语言模型与知识图谱的深度融合,在参数和任务层面实现协同优化。这不仅推动了两大研究领域的交叉融通,也为复杂智能系统的构建奠定了基础。

在实践层面,本文方法有望显著提升知识获取和应用的自动化水平。一方面,减轻了对人工标注数据和规则的依赖,节约了知识构建成本;另一方面,拓展了单一语料的知识获取广度,加速了知识图谱的更新迭代。更重要的是,将结构化知识引入语言模型的表示和推理过程,赋予其可解释、可追溯的特性。这为从数据驱动走向知识驱动铺平了道路。可以预见,随着大语言模型与知识图谱的进一步融合,我们有望构建出兼具规模、质量、常识的超大规模知识库,为智能搜索、智能问答、智能决策等应用注入新动能。

展望未来,大语言模型与知识图谱融合仍有许多问题值得进一步探索:

(1)知识表示:如何统一语言模型的分布式表示和知识图谱的符号化表示?如何实现概念、实例、关系的精准对齐和映射?

(2)模型训练:如何在保留大语言模型泛化性的同时,进一步提升其领域适应性?是否可以将结构化知识融入预训练目标?

(3)推理机制:如何更好地利用大语言模型的常识推理能力,发现隐含知识?如何引入因果和逻辑规则,约束生成式知识抽取?

(4)人机协同:专家反馈如何指导模型微调?主动学习如何选择最有价值的数据?如何设计可解释、可交互的系统?

(5)知识应用:大语言模型驱动的知识图谱在问答、对话、推荐等任务中的应用价值如何?能否与现有符号推理系统互补?

这些问题的解决有赖于自然语言处理、知识工程、机器学习等多个领域的交叉创新。我们相信,随着人工智能研究的不断深入,大语言模型与知识图谱的融合势必成为知识获取和应用的主流范式。这不仅将极大拓展人类认知的广度和深度,也必将开创智慧社会的崭新图景。让我们携手探索前沿,共同开启知识智能的新纪元!

参考文献

[1] 孙茂松,曹存根,黄居仁.知识图谱:概念与技术.电子工业出版社,2020.

[2] Bollacker K,Tufts P,Pierce T,et al.A platform for scalable,collaborative,structured information integration.AAAI Workshop: AI and Web,2007.

[3] Lehmann J,Isele R,Jakob M,et al.DBpedia–A large-scale,multilingual knowledge base extracted from Wikipedia.Semantic Web,2015.

[4] Suchanek F M,Kasneci G,Weikum G.Yago: A core of semantic knowledge.WWW,2007: 697-706.

[5] 桂勋,周红,王海峰,等.知识图谱技术综述.计算机研究与发展,2016,53(4):691-701.

[6] Carlson A,Betteridge J,Kisiel B,et al.Toward an Architecture for Never-Ending Language Learning.AAAI,2010.

[7] Dong X,Gabrilovich E,Heitz G,et al.Knowledge vault: A web-scale approach to probabilistic knowledge fusion.SIGKDD,2014.

[8] Chen H,Liu X,Yin D,et al.A survey on dialogue systems: Recent advances and new frontiers.ACM SIGKDD Explorations Newsletter.2017.

[9] Vaswani A,Shazeer N,Parmar N,et al.Attention is All you Need.NIPS.2017:5998-6008.

[10] Devlin J,Chang M W,Lee K,et al.BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.NAACL.2019.

[11] Radford A,Wu J,Child R,et al.Language Models are Unsupervised Multitask Learners.OpenAI blog.2019.

[12] Raffel C,Shazeer N,Roberts A,et al.Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.JMLR.2020.

[13] Lan Z,Chen M,Goodman S,et al.ALBERT: A Lite BERT for Self-supervised Learning of Language Representations.ICLR.2020.

[14] Yang Z,Dai Z,Yang Y,et al.XLNet: Generalized Autoregressive Pretraining for Language Understanding.NeurIPS.2019.

[15] Brown T,Mann B,Ryder N,et al.Language Models are Few-Shot Learners.NeurIPS.2020.

[16] Sun Yu,et al.ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation.ArXiv.2021.

[17] Xiong C,Power R,Callan J.Explicit semantic ranking for academic search via knowledge graph embedding.WWW,2017.

[18] Yu M,Yin W,Hasan K S,et al.Improved neural relation detection for knowledge base question answering.ACL.2017.

[19] Lin Y,Liu Z,Sun M.Neural Relation Extraction with Multi-lingual Attention.ACL.2017.

[20] Zhang Z,Han X,Liu Z,et al.ERNIE: Enhanced Language Representation with Informative

[21] Peters M,Neumann M,Logan R,et al.Knowledge enhanced contextual word representations.EMNLP.2019.

[22] Liu W,Zhou P,Zhao Z,et al.K-bert: Enabling language representation with knowledge graph.AAAI.2020.

[23] Wang X,Gao T,Zhu Z,et al.KEPLER: A unified model for knowledge embedding and pre-trained language representation.TACL.2021.

[24] Wang X,Gao T,Zhu Z,et al.K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters.ACL Findings.2021.

[25] Wang R,Tang D,Duan N,et al.K-Plug: Knowledge-Injected Pre-trained Language Model for Natural Language Understanding.arXiv.2021.

[26] Qin X,Feng H,Fu X,et al.ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning.ACL.2021.

[27] 刘康,赵军.知识图谱嵌入:算法、应用与展望.自动化学报,2020,46(8):1436-1453.

[28] Han X,Gao T,Lin Y,et al.More data,more relations, more context and more openness: A review and outlook for relation extraction.ACL.2021:745-758.

[29] Lin Y,Liu Z,Sun M,et al.Neural relation extraction with selective attention over instances.ACL.2016,2124-2133.

[30] Nathani D,Chauhan J,Sharma C,et al.Learning attention-based embeddings for relation prediction in knowledge graphs.ACL.2019: 4710-4723.

[31] Bommasani R,Hudson D A,Adeli E,et al.On the opportunities and risks of foundation models.arXiv.2021.human

[32] Beltagy I,Peters M E,Cohan A.Longformer: The long-document transformer.arXiv.2020.

[33] Shen T,Geng Y,Qin T,et al.Knowledge-aware Language Model Pretraining via Generative and Discriminative Learning.arXiv.2022.

[34] Xu B,Zhang Y,Liang J,et al.CN-DBpedia: A Never-Ending Chinese Knowledge Extraction System.IEA/AIE.2017.

[35] Li D,Hu X,Lin Y,et al.DuIE: A Large-scale Chinese Dataset for Information Extraction.NLPCC.2019.

[36] He S,Liu K,Zhao J,et al.CMEKG:Construction and Applications of a Chinese Medical Knowledge Graph.ISWC.2018:

[37] Riedel S,Yao L,McCallum A.Modeling relations and their mentions without labeled text. ECML-PKDD.2010:148-163.

[38] Bordes A,Usunier N,Garcia-Duran A,et al.Translating embeddings for modeling multi-relational data.NeurIPS.2013.

[39] Zhu Z,Xu H,Xie R,et al.GraphVite:A High-Performance CPU-GPU Hybrid System for Node Embedding.WWW.2019.

[40] Han X,Zhu H,Yu P,et al.FewRel:A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation.EMNLP.2018.

[41] Wei Z,Su J,Wang Y,et al.A Novel Cascade Binary Tagging Framework for Relational Triple Extraction.ACL.2020:1476-1488.
