你是一名人工智能科学家。
请帮我写一篇名为《融合大语言模型与深度学习的知识图谱构建研究》的8000字论文。
这篇论文主要提出了将大语言模型（如chatgpt和claude）与深度学习融合构建知识图谱的方法llm-dl-kg。

该方法将利用大语言模型解决深度学习构建知识图谱如下问题：
1.数据质量和多样性
（1）预训练知识：大语言模型通过在大规模文本数据集上进行预训练，已经内嵌了丰富的通用知识和领域知识。这使得它们在处理数据质量问题和提升对少见实体或概念的识别能力方面具有优势。
（2）数据增强：大语言模型可以用于生成合成数据或对现有数据进行增强，增加训练数据的多样性和覆盖范围，从而提高模型在特定任务上的性能和泛化能力。
2.模型复杂性和解释性
（1）迁移学习：通过利用大语言模型的迁移学习能力，可以在特定任务上仅需相对较少的定制化训练即可达到较高的性能，这降低了模型训练的复杂性和资源需求。
（2）解释性工具和技术：虽然大语言模型本身的解释性仍是挑战，但已有研究致力于开发针对这些模型的解释性工具和技术，如注意力机制可视化，帮助理解模型的决策过程。
3.实体识别和关系抽取
（1）强大的语言理解能力：大语言模型在理解语境、抽象概念和实体间复杂关系方面展现出强大能力，这对于准确识别文本中的实体和它们之间的关系至关重要。
（2）端到端学习：大语言模型支持端到端的学习方式，能够直接从原始文本数据中学习到实体识别和关系抽取的任务，减少了传统方法中需要的复杂特征工程和预处理步骤。
4.知识一致性和时效性
（1）持续学习：某些大语言模型框架支持持续学习，允许模型在接受新信息时更新其知识库，这有助于维护知识图谱的一致性和时效性。
（2）知识融合能力：大语言模型可用于整合和融合来自不同来源的信息，通过理解和处理信息中的冲突和重复，帮助构建更一致、准确的知识图谱。

项目的实验分为两个方面：
1.在测试数据上 比较chatgpt、claude和bard 三种大语言模型构建知识图谱效果
2.在测试数据上，最好的大语言模型与深度学习模型结合与单独使用深度学习在时间和准确性上的比较

实现细节:实验在配备国产A1000 DPU的服务器上进行。超参数通过网格搜索确定,batch size、学习率分别设为64和1e-5。
模型采用PyTorch实现,并使用Huggingface的Transformer库。
为缓解标注数据规模有限的问题,我们在NYT和PubMed上采用5折交叉验证,并报告平均值。知识库存储和查询使用图数据库Neo4j。

实验测试:中英文大语言模型
包括BERT、RoBERTa、ERNIE、GPT2、GPT3等。
为比较不同模型的效果,实验分别使用它们作为知识增强的底座模型。
在中文数据集上,我们选用BERT-wwm和RoBERTa-wwm的中文版;
在英文数据集上,选用BERT-large和GPT-2。

测试数据：
(1)CN-DBpedia:中文知识图谱,包含 1000 万实体和 6000 万关系,知识涵盖概念、实例、属性等多个类别。
(2)OwnThink:开放域中文知识图谱,包含 1.4 亿实体和 2.4 亿关系,融合百度百科、互动百科等多个来源。
(3)OpenKG:多源融合的中文开放知识图谱,收录了1.4亿实体、43亿属性三元组。我们选择其中的8个常见关系类型,采样50万三元组作为实验语料。
(4)NYT:New York Times英文新闻语料,带有标注的实体、关系和事件。我们使用预处理后的2010-2013年语料,包含67,537个句子和217,132个关系事实。
(5)PubMed:生物医学文献知识图谱,从PubMed论文摘要中提取疾病、药物、基因等实体及其关系。包含134万节点、250万条边。该数据集代表了特定领域知识图谱构建的挑战。

测试结果以markdown列表方式显示

论文的基本结构，包括一下基本部分：
摘要（目的、方法、结果、局限、结论）
1.引言
2.相关研究
3.方法（简介，结合公式、流程图、系统结构图详细说明算法）
4.实验设计和结果分析（评价标准，实验设计与分析）
5.结语
参考文献（中文，英文）

请根据以上需求请详细设计论文每个部分，是否清楚我的指令。